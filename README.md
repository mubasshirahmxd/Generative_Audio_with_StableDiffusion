<!-- PROJECT HEADER -->

<h1 align="center">ğŸ§ Generative Audio with Stable Diffusion (No-API)</h1>
<h3 align="center">Text â†’ Audio Generation using Stable Audio by Stability AI</h3>

<p align="center">
  <img src="https://img.shields.io/badge/Python-3.10+-green?style=for-the-badge">
  <img src="https://img.shields.io/badge/Diffusers-Stable%20Audio-blue?style=for-the-badge">
  <img src="https://img.shields.io/badge/HuggingFace-Models-orange?style=for-the-badge">
  <img src="https://img.shields.io/badge/Jupyter-Notebook-yellow?style=for-the-badge">
  <img src="https://img.shields.io/badge/Status-Active-success?style=for-the-badge">
</p>

---

# ğŸŒŸ Overview

This project demonstrates **state-of-the-art Text-to-Audio generation** using:

âœ” Stable Audio â€“ *Stability AIâ€™s open-source generative audio model*
âœ” HuggingFace Diffusers
âœ” PyTorch
âœ” Jupyter Notebook workflow

You simply provide a **text prompt**, and the model synthesizes a **high-quality audio clip** (e.g., nature sounds, music, SFX, ambient noise).

---

# ğŸ“ Project Structure

```
01_Generative_Audio_with_StableDiffusion/
â”œâ”€ assets/
â”‚  â”œâ”€ stable_audio_output.wav
â”‚  â”œâ”€ stable_audio_output.wav.meta.json
â”‚  â””â”€ stable_audio_output1.wav
â””â”€ notebooks/
   â””â”€ 01_StableDiffusion_text2audio.ipynb
```

---

# ğŸ§ Sample Outputs

### ğŸ”Š **Sample Output 1**

`assets/stable_audio_output.wav`

### ğŸ”Š **Sample Output 2**

`assets/stable_audio_output1.wav`

These were generated using Stable Audio with prompts like:

> â€œElephant trumpet sound with deep resonance in a forest, cinematic ambience.â€

---

# ğŸš€ Features

### ğŸŒˆ **Text â†’ Audio Generation**

Turn simple text prompts into rich audio.

### ğŸ¼ **Multiple Waveform Outputs**

Generate multiple variations per prompt.

### ğŸ§  **Reproducibility**

Uses deterministic seeds for consistent audio.

### ğŸ’¾ **Automatic Saving**

Generated audio clips are saved as `.wav`.

### ğŸ”¥ **High-quality generation**

Leverages Stability AI's `stable-audio-open-1.0` model.

---

# ğŸ›  Installation

### 1ï¸âƒ£ Create & activate a virtual environment (optional)

```bash
conda create -n audio_env python=3.10
conda activate audio_env
```

### 2ï¸âƒ£ Install dependencies

```bash
pip install torch diffusers soundfile huggingface_hub accelerate
```

### 3ï¸âƒ£ Login to HuggingFace

```bash
huggingface-cli login
```

---

# ğŸ“’ Run the Notebook

Open:

```
notebooks/01_StableDiffusion_text2audio.ipynb
```

Run all cells to:

âœ” Load Stable Audio
âœ” Provide prompts
âœ” Generate & save `.wav` files

---

# ğŸ“ Example Prompts (Copy-Paste Ready)

### ğŸµ Music

```
Lo-fi beat with vinyl crackle, warm piano chords, soft drums at 70 BPM.
```

### ğŸ˜ Animal SFX

```
Elephant trumpet sound with deep resonance in a forest, cinematic ambience.
```

### ğŸŒ§ Nature & Atmosphere

```
Meditative rain with distant thunder and soft wind chimes.
```

### ğŸš€ Sci-Fi

```
Spaceship engine hum with low-frequency vibration and metallic resonance.
```

### ğŸ™ Urban Ambience

```
Busy street ambiance with cars passing and soft human chatter.
```

---

# ğŸ§© Code Preview

```python
from diffusers import StableAudioPipeline
import torch, soundfile as sf

pipe = StableAudioPipeline.from_pretrained(
    "stabilityai/stable-audio-open-1.0",
    torch_dtype=torch.float16
).to("cuda")

audio = pipe(
    prompt="Elephant trumpet sound",
    audio_end_in_s=10,
    num_inference_steps=200,
).audios[0]

sf.write("output.wav", audio.T.cpu().numpy(), pipe.vae.sampling_rate)
```

---

# ğŸ“˜ Documentation Included

âœ” Notebook explanation
âœ” Working audio examples
âœ” Prompt library
âœ” Metadata (`.meta.json`)

---

# ğŸ¤ Contribution

Pull requests are welcome!Feel free to add:

- New prompts
- New audio outputs
- Improvements in notebook

---

# â­ Support the Project

If you like this work, please â­ star the repository â€” it motivates continuous improvements!

---

# ğŸ“ License

This project is for **educational / research purposes only**.
Audio model belongs to **Stability AI** under their respective license.

---
